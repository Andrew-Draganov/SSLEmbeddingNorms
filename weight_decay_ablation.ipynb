{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running simclr comparisons using config at configs/simclr_default.yml\n",
      "Dataset: cifar10\n",
      "Current experiment being run:\n",
      "Model: simclr; Experiment name: no_wd\n",
      "Values being changed: {'resnet_version': 18, 'weight_decay': 0, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4}\n",
      "\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                    | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1, SimCLR loss: 4.8916: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:12<00:00, 16.25it/s]\n",
      "Train epoch 2, SimCLR loss: 4.7066: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 17.09it/s]\n",
      "Train epoch 3, SimCLR loss: 4.5703: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.98it/s]\n",
      "Train epoch 4, SimCLR loss: 4.4521: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/repos/contrastive_learning_analysis/CLA/training/lin_evaluator.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pre_model.load_state_dict(torch.load('{}_epoch{}.pt'.format(pre_model_str, load_epoch)))\n",
      "kNN: 100%|████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 45.61it/s, Accuracy=45.2]\n",
      "Train epoch 1, loss: 1.6272, acc: 0.4105: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.36it/s]\n",
      "Test epoch 1, loss: 1.5007, acc: 0.4473: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 47.99it/s]\n",
      "Train epoch 2, loss: 1.4924, acc: 0.4571: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.42it/s]\n",
      "Test epoch 2, loss: 1.4484, acc: 0.4784: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 47.88it/s]\n",
      "Train epoch 5, SimCLR loss: 4.3492: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.96it/s]\n",
      "Train epoch 6, SimCLR loss: 4.2764: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.93it/s]\n",
      "Train epoch 7, SimCLR loss: 4.2235: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.92it/s]\n",
      "Train epoch 8, SimCLR loss: 4.1780: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kNN: 100%|████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 46.48it/s, Accuracy=55.4]\n",
      "Train epoch 1, loss: 1.3175, acc: 0.5321: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.34it/s]\n",
      "Test epoch 1, loss: 1.2163, acc: 0.5579: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 47.82it/s]\n",
      "Train epoch 2, loss: 1.1884, acc: 0.5728: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.36it/s]\n",
      "Test epoch 2, loss: 1.1549, acc: 0.5872: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 47.82it/s]\n",
      "/home/andrew/repos/contrastive_learning_analysis/CLA/experiments/model_comparison.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('{}_epoch{}.pt'.format(model_str, checkpoint)))\n",
      "Calculating train set embeddings for checkpoint 1: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.50it/s]\n",
      "Calculating test set embeddings for checkpoint 1: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.14it/s]\n",
      "Calculating train set embeddings for checkpoint 2: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.46it/s]\n",
      "Calculating test set embeddings for checkpoint 2: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.02it/s]\n",
      "Calculating train set embeddings for checkpoint 4: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.49it/s]\n",
      "Calculating test set embeddings for checkpoint 4: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.32it/s]\n",
      "Calculating train set embeddings for checkpoint 8: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.49it/s]\n",
      "Calculating test set embeddings for checkpoint 8: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset: cifar10\n",
      "Current experiment being run:\n",
      "Model: simclr; Experiment name: tiny_wd\n",
      "Values being changed: {'resnet_version': 18, 'weight_decay': 1e-08, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4}\n",
      "\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                    | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1, SimCLR loss: 4.8822: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.92it/s]\n",
      "Train epoch 2, SimCLR loss: 4.6930: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.87it/s]\n",
      "Train epoch 3, SimCLR loss: 4.5552: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.84it/s]\n",
      "Train epoch 4, SimCLR loss: 4.4487: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kNN: 100%|████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 47.04it/s, Accuracy=45.8]\n",
      "Train epoch 1, loss: 1.5995, acc: 0.4194: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.33it/s]\n",
      "Test epoch 1, loss: 1.5019, acc: 0.4618: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 48.38it/s]\n",
      "Train epoch 2, loss: 1.4810, acc: 0.4645: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.43it/s]\n",
      "Test epoch 2, loss: 1.4596, acc: 0.4681: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 47.61it/s]\n",
      "Train epoch 5, SimCLR loss: 4.3554: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.87it/s]\n",
      "Train epoch 6, SimCLR loss: 4.2810: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.90it/s]\n",
      "Train epoch 7, SimCLR loss: 4.2267: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.88it/s]\n",
      "Train epoch 8, SimCLR loss: 4.1847: 100%|██████████████████████████████████████████████████████████████████████| 195/195 [00:11<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kNN: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 46.88it/s, Accuracy=54]\n",
      "Train epoch 1, loss: 1.3305, acc: 0.5254: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.40it/s]\n",
      "Test epoch 1, loss: 1.2224, acc: 0.5622: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 47.73it/s]\n",
      "Train epoch 2, loss: 1.1972, acc: 0.5694: 100%|████████████████████████████████████████████████████████████████| 195/195 [00:07<00:00, 25.40it/s]\n",
      "Test epoch 2, loss: 1.1986, acc: 0.5656: 100%|███████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 48.27it/s]\n",
      "Calculating train set embeddings for checkpoint 1: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.49it/s]\n",
      "Calculating test set embeddings for checkpoint 1: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.05it/s]\n",
      "Calculating train set embeddings for checkpoint 2: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.46it/s]\n",
      "Calculating test set embeddings for checkpoint 2: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.14it/s]\n",
      "Calculating train set embeddings for checkpoint 4: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.47it/s]\n",
      "Calculating test set embeddings for checkpoint 4: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.50it/s]\n",
      "Calculating train set embeddings for checkpoint 8: 100%|███████████████████████████████████████████████████████| 195/195 [00:26<00:00,  7.47it/s]\n",
      "Calculating test set embeddings for checkpoint 8: 100%|██████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 36.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from CLA.experiments.model_comparison import train_comparisons\n",
    "# os.chdir('/path/to/contrastive_learning_analysis')\n",
    "\n",
    "simclr_wd_experiments = [\n",
    "    {\n",
    "        'resnet_version': 18,\n",
    "        'weight_decay': 0,\n",
    "        'epochs': 8, # how many epochs to train for. Set to 8 for verification purposes but feel free to set higher.\n",
    "        'log_start_epoch': 1, # when saving embeddings, this is the first checkpoint to start from\n",
    "        'eval_load_epoch': 8, # when doing finetuning at the end of training, this is the checkpoint to load\n",
    "        'first_finetune': 4 # first epoch at which to start fitting classifiers during training\n",
    "    },\n",
    "    {'resnet_version': 18, 'weight_decay': 1e-8, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4},\n",
    "    {'resnet_version': 18, 'weight_decay': 1e-6, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4}, # default wd\n",
    "    {'resnet_version': 18, 'weight_decay': 1e-4, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4}\n",
    "]\n",
    "simsiam_wd_experiments = [\n",
    "    {'resnet_version': 18, 'weight_decay': 0, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4},\n",
    "    {'resnet_version': 18, 'weight_decay': 5e-6, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4},\n",
    "    {'resnet_version': 18, 'weight_decay': 5e-4, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4}, # default wd\n",
    "    {'resnet_version': 18, 'weight_decay': 5e-2, 'epochs': 8, 'log_start_epoch': 1, 'eval_load_epoch': 8, 'first_finetune': 4}\n",
    "]\n",
    "\n",
    "experiment_names = [\n",
    "    'no_wd',\n",
    "    'tiny_wd',\n",
    "    'default_wd',\n",
    "    'large_wd'\n",
    "]\n",
    "log_dir = 'wd_sweep'\n",
    "\n",
    "train_comparisons(\n",
    "    'simclr',\n",
    "    'cifar10',\n",
    "    simclr_wd_experiments,\n",
    "    experiment_names,\n",
    "    log_dir=log_dir,\n",
    "    finetune_at_end=False, # No need to do final classification check since we already did it during training\n",
    "    do_training=True, # We want to run training. If you already did training and just want to load checkpoints, set this to False\n",
    "    save_off=True # Set to true if you want to save embeddings from various checkpoints\n",
    ")\n",
    "\n",
    "# Uncomment this if you also want to train simsiam experiments\n",
    "\n",
    "# train_comparisons(\n",
    "#     'simsiam',\n",
    "#     'cifar10',\n",
    "#     simsiam_wd_experiments,\n",
    "#     experiment_names,\n",
    "#     log_dir='wd_sweep',\n",
    "#     finetune_at_end=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 49920, 128)\n",
      "(4, 49920)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "embedding_layer = 'projector'\n",
    "dataset = 'cifar10'\n",
    "log_dir = 'wd_sweep'\n",
    "\n",
    "train_embeddings = {}\n",
    "train_targets = {}\n",
    "test_embeddings = {}\n",
    "test_targets = {}\n",
    "embedding_norms = {}\n",
    "test_embedding_norms = {}\n",
    "knn_classifiers = {}\n",
    "\n",
    "# Load all embeddings and labels into dictionaries\n",
    "for model_str in ['simclr', 'simsiam']:\n",
    "    # Set up dictionaries to store all experiments' embeddings\n",
    "    train_embeddings[model_str] = {}\n",
    "    train_targets[model_str] = {}\n",
    "    test_embeddings[model_str] = {}\n",
    "    test_targets[model_str] = {}\n",
    "    embedding_norms[model_str] = {}\n",
    "    test_embedding_norms[model_str] = {}\n",
    "    knn_classifiers[model_str] = {}\n",
    "    \n",
    "    for exp_name in experiment_names:\n",
    "        embeddings_dir = os.path.join(os.getcwd(), 'outputs', dataset, model_str, log_dir, exp_name, 'ablations')\n",
    "        \n",
    "        train_embeddings[model_str][exp_name] = np.squeeze(np.load(os.path.join(embeddings_dir, 'train_embeddings.npy'), allow_pickle=True)[()][embedding_layer])\n",
    "        train_targets[model_str][exp_name] = np.squeeze(np.load(os.path.join(embeddings_dir, 'train_targets.npy'), allow_pickle=True)[()])\n",
    "        \n",
    "        test_embeddings[model_str][exp_name] = np.squeeze(np.load(os.path.join(embeddings_dir, 'test_embeddings.npy'), allow_pickle=True)[()][embedding_layer])\n",
    "        test_targets[model_str][exp_name] = np.squeeze(np.load(os.path.join(embeddings_dir, 'test_targets.npy'), allow_pickle=True)[()])\n",
    "    \n",
    "        embedding_norms[model_str][exp_name] = np.sqrt(np.sum(np.square(train_embeddings[model_str][exp_name]), axis=-1))\n",
    "        test_embedding_norms[model_str][exp_name] = np.sqrt(np.sum(np.square(test_embeddings[model_str][exp_name]), axis=-1))\n",
    "\n",
    "\n",
    "print(train_embeddings['simclr']['no_wd'].shape)\n",
    "print(embedding_norms['simclr']['no_wd'].shape)\n",
    "\n",
    "# You should get shapes [4, 49920, 128] and [4, 49920] respectively.\n",
    "# The four corresponds to the four checkpoints at epochs 1, 2, 4 and 8.\n",
    "#     - if you run this for 128 epochs, you'd have more checkpoints saved\n",
    "# The 49920 is the number of data samples in the cifar train set after you throw away the last incomplete batch.\n",
    "# 128 is the embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
